{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, LSTM, Flatten, Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_X_Y(nb):\n",
    "    X_fname = \"data/Xtr{}.csv\".format(nb)\n",
    "    DNAs = pd.read_csv(X_fname).seq\n",
    "    X = []\n",
    "    for DNA in DNAs:\n",
    "        l_to_id = {\"T\": 0, \"G\": 1, \"C\": 2, \"A\": 3}\n",
    "        X.append([l_to_id[l] for l in DNA])\n",
    "    X = to_categorical(X, num_classes=4)\n",
    "\n",
    "    Y_fname = \"data/Ytr{}.csv\".format(nb)\n",
    "    Y = pd.read_csv(Y_fname).Bound\n",
    "    Y = to_categorical(Y, num_classes=2)\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = load_X_Y(0)\n",
    "X_shape = X.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_37 (Embedding)     (None, 101, 1)            4         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 72, 16)            496       \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 53, 16)            5136      \n",
      "_________________________________________________________________\n",
      "flatten_30 (Flatten)         (None, 848)               0         \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 100)               84900     \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 90,738\n",
      "Trainable params: 90,738\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(32, 30, activation=\"relu\"))\n",
    "model.add(MaxPooling1D(10, 5))\n",
    "model.add(Conv1D(32, 10, activation=\"relu\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation=\"relu\"))\n",
    "model.add(Dense(2, activation=\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=Adam(lr=0.0001),\n",
    "              metrics=[\"acc\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1800 samples, validate on 200 samples\n",
      "Epoch 1/100\n",
      "1800/1800 [==============================] - 4s 2ms/step - loss: 0.6931 - acc: 0.5100 - val_loss: 0.6927 - val_acc: 0.5150\n",
      "Epoch 2/100\n",
      "1800/1800 [==============================] - 1s 318us/step - loss: 0.6924 - acc: 0.5178 - val_loss: 0.6922 - val_acc: 0.5100\n",
      "Epoch 3/100\n",
      "1800/1800 [==============================] - 1s 322us/step - loss: 0.6914 - acc: 0.5194 - val_loss: 0.6913 - val_acc: 0.5050\n",
      "Epoch 4/100\n",
      "1800/1800 [==============================] - 1s 321us/step - loss: 0.6893 - acc: 0.5683 - val_loss: 0.6900 - val_acc: 0.5200\n",
      "Epoch 5/100\n",
      "1800/1800 [==============================] - 1s 330us/step - loss: 0.6862 - acc: 0.5528 - val_loss: 0.6873 - val_acc: 0.5550\n",
      "Epoch 6/100\n",
      "1800/1800 [==============================] - 1s 325us/step - loss: 0.6822 - acc: 0.5900 - val_loss: 0.6846 - val_acc: 0.5300\n",
      "Epoch 7/100\n",
      "1800/1800 [==============================] - 1s 332us/step - loss: 0.6776 - acc: 0.5839 - val_loss: 0.6834 - val_acc: 0.5300\n",
      "Epoch 8/100\n",
      "1800/1800 [==============================] - 1s 338us/step - loss: 0.6719 - acc: 0.5906 - val_loss: 0.6816 - val_acc: 0.5650\n",
      "Epoch 9/100\n",
      "1800/1800 [==============================] - 1s 390us/step - loss: 0.6671 - acc: 0.6011 - val_loss: 0.6809 - val_acc: 0.5400\n",
      "Epoch 10/100\n",
      "1800/1800 [==============================] - 1s 346us/step - loss: 0.6649 - acc: 0.5950 - val_loss: 0.6808 - val_acc: 0.5300\n",
      "Epoch 11/100\n",
      "1800/1800 [==============================] - 1s 350us/step - loss: 0.6614 - acc: 0.6078 - val_loss: 0.6813 - val_acc: 0.5350\n",
      "Epoch 12/100\n",
      "1800/1800 [==============================] - 1s 357us/step - loss: 0.6588 - acc: 0.6089 - val_loss: 0.6823 - val_acc: 0.5200\n",
      "Epoch 13/100\n",
      "1800/1800 [==============================] - 1s 357us/step - loss: 0.6547 - acc: 0.6294 - val_loss: 0.6844 - val_acc: 0.5450\n",
      "Epoch 14/100\n",
      "1800/1800 [==============================] - 1s 351us/step - loss: 0.6549 - acc: 0.6139 - val_loss: 0.6832 - val_acc: 0.5350\n",
      "Epoch 15/100\n",
      "1800/1800 [==============================] - 1s 358us/step - loss: 0.6499 - acc: 0.6250 - val_loss: 0.6844 - val_acc: 0.5300\n",
      "Epoch 16/100\n",
      "1800/1800 [==============================] - 1s 397us/step - loss: 0.6494 - acc: 0.6222 - val_loss: 0.6880 - val_acc: 0.5400\n",
      "Epoch 17/100\n",
      "1800/1800 [==============================] - 1s 382us/step - loss: 0.6440 - acc: 0.6372 - val_loss: 0.6845 - val_acc: 0.5300\n",
      "Epoch 18/100\n",
      "1800/1800 [==============================] - 1s 412us/step - loss: 0.6414 - acc: 0.6367 - val_loss: 0.6874 - val_acc: 0.5550\n",
      "Epoch 19/100\n",
      "1800/1800 [==============================] - 1s 423us/step - loss: 0.6387 - acc: 0.6411 - val_loss: 0.6861 - val_acc: 0.5250\n",
      "Epoch 20/100\n",
      "1800/1800 [==============================] - 1s 357us/step - loss: 0.6360 - acc: 0.6517 - val_loss: 0.6872 - val_acc: 0.5300\n",
      "Epoch 21/100\n",
      "1800/1800 [==============================] - 1s 419us/step - loss: 0.6325 - acc: 0.6428 - val_loss: 0.6883 - val_acc: 0.5400\n",
      "Epoch 22/100\n",
      "1800/1800 [==============================] - 1s 421us/step - loss: 0.6304 - acc: 0.6489 - val_loss: 0.6894 - val_acc: 0.5400\n",
      "Epoch 23/100\n",
      "1800/1800 [==============================] - 1s 369us/step - loss: 0.6284 - acc: 0.6461 - val_loss: 0.6901 - val_acc: 0.5550\n",
      "Epoch 24/100\n",
      "1800/1800 [==============================] - 1s 355us/step - loss: 0.6232 - acc: 0.6578 - val_loss: 0.6923 - val_acc: 0.5350\n",
      "Epoch 25/100\n",
      "1800/1800 [==============================] - 1s 365us/step - loss: 0.6206 - acc: 0.6611 - val_loss: 0.6913 - val_acc: 0.5500\n",
      "Epoch 26/100\n",
      "1800/1800 [==============================] - 1s 407us/step - loss: 0.6173 - acc: 0.6622 - val_loss: 0.6937 - val_acc: 0.5500\n",
      "Epoch 27/100\n",
      "1800/1800 [==============================] - 1s 365us/step - loss: 0.6135 - acc: 0.6678 - val_loss: 0.6941 - val_acc: 0.5450\n",
      "Epoch 28/100\n",
      "1800/1800 [==============================] - 1s 369us/step - loss: 0.6111 - acc: 0.6650 - val_loss: 0.6954 - val_acc: 0.5400\n",
      "Epoch 29/100\n",
      "1800/1800 [==============================] - 1s 374us/step - loss: 0.6069 - acc: 0.6750 - val_loss: 0.6961 - val_acc: 0.5350\n",
      "Epoch 30/100\n",
      "1800/1800 [==============================] - 1s 385us/step - loss: 0.6033 - acc: 0.6800 - val_loss: 0.6940 - val_acc: 0.5550\n",
      "Epoch 31/100\n",
      "1800/1800 [==============================] - 1s 377us/step - loss: 0.5987 - acc: 0.6817 - val_loss: 0.6980 - val_acc: 0.5500\n",
      "Epoch 32/100\n",
      "1800/1800 [==============================] - 1s 371us/step - loss: 0.5944 - acc: 0.6906 - val_loss: 0.6982 - val_acc: 0.5600\n",
      "Epoch 33/100\n",
      "1800/1800 [==============================] - 1s 376us/step - loss: 0.5915 - acc: 0.7000 - val_loss: 0.7040 - val_acc: 0.5500\n",
      "Epoch 34/100\n",
      "1800/1800 [==============================] - 1s 515us/step - loss: 0.5875 - acc: 0.6900 - val_loss: 0.7005 - val_acc: 0.5650\n",
      "Epoch 35/100\n",
      "1800/1800 [==============================] - 1s 512us/step - loss: 0.5813 - acc: 0.7006 - val_loss: 0.7054 - val_acc: 0.5650\n",
      "Epoch 36/100\n",
      "1800/1800 [==============================] - 1s 487us/step - loss: 0.5769 - acc: 0.7133 - val_loss: 0.7048 - val_acc: 0.5450\n",
      "Epoch 37/100\n",
      "1800/1800 [==============================] - 1s 498us/step - loss: 0.5714 - acc: 0.7106 - val_loss: 0.7039 - val_acc: 0.5650\n",
      "Epoch 38/100\n",
      "1800/1800 [==============================] - 1s 492us/step - loss: 0.5670 - acc: 0.7194 - val_loss: 0.7068 - val_acc: 0.5350\n",
      "Epoch 39/100\n",
      "1800/1800 [==============================] - 1s 464us/step - loss: 0.5599 - acc: 0.7283 - val_loss: 0.7084 - val_acc: 0.5750\n",
      "Epoch 40/100\n",
      "1800/1800 [==============================] - 1s 485us/step - loss: 0.5543 - acc: 0.7283 - val_loss: 0.7113 - val_acc: 0.5450\n",
      "Epoch 41/100\n",
      "1800/1800 [==============================] - 1s 512us/step - loss: 0.5476 - acc: 0.7356 - val_loss: 0.7141 - val_acc: 0.5900\n",
      "Epoch 42/100\n",
      "1800/1800 [==============================] - 1s 457us/step - loss: 0.5444 - acc: 0.7367 - val_loss: 0.7293 - val_acc: 0.5800\n",
      "Epoch 43/100\n",
      "1800/1800 [==============================] - 1s 446us/step - loss: 0.5386 - acc: 0.7411 - val_loss: 0.7166 - val_acc: 0.5650\n",
      "Epoch 44/100\n",
      "1800/1800 [==============================] - 1s 472us/step - loss: 0.5311 - acc: 0.7500 - val_loss: 0.7202 - val_acc: 0.5850\n",
      "Epoch 45/100\n",
      "1800/1800 [==============================] - 1s 455us/step - loss: 0.5240 - acc: 0.7617 - val_loss: 0.7207 - val_acc: 0.5650\n",
      "Epoch 46/100\n",
      "1800/1800 [==============================] - 1s 486us/step - loss: 0.5165 - acc: 0.7572 - val_loss: 0.7243 - val_acc: 0.5600\n",
      "Epoch 47/100\n",
      "1800/1800 [==============================] - 1s 471us/step - loss: 0.5109 - acc: 0.7694 - val_loss: 0.7231 - val_acc: 0.5950\n",
      "Epoch 48/100\n",
      "1800/1800 [==============================] - 1s 471us/step - loss: 0.5051 - acc: 0.7744 - val_loss: 0.7261 - val_acc: 0.5900\n",
      "Epoch 49/100\n",
      "1800/1800 [==============================] - 1s 472us/step - loss: 0.4945 - acc: 0.7800 - val_loss: 0.7410 - val_acc: 0.5400\n",
      "Epoch 50/100\n",
      "1800/1800 [==============================] - 1s 472us/step - loss: 0.4894 - acc: 0.7839 - val_loss: 0.7326 - val_acc: 0.5800\n",
      "Epoch 51/100\n",
      "1800/1800 [==============================] - 1s 472us/step - loss: 0.4891 - acc: 0.7828 - val_loss: 0.7450 - val_acc: 0.5750\n",
      "Epoch 52/100\n",
      "1800/1800 [==============================] - 1s 520us/step - loss: 0.4774 - acc: 0.7950 - val_loss: 0.7440 - val_acc: 0.5900\n",
      "Epoch 53/100\n",
      "1800/1800 [==============================] - 1s 492us/step - loss: 0.4695 - acc: 0.8017 - val_loss: 0.7450 - val_acc: 0.5850\n",
      "Epoch 54/100\n",
      "1800/1800 [==============================] - 1s 552us/step - loss: 0.4589 - acc: 0.8017 - val_loss: 0.7475 - val_acc: 0.5650\n",
      "Epoch 55/100\n",
      "1800/1800 [==============================] - 1s 525us/step - loss: 0.4508 - acc: 0.8100 - val_loss: 0.7566 - val_acc: 0.5900\n",
      "Epoch 56/100\n",
      "1800/1800 [==============================] - 1s 476us/step - loss: 0.4499 - acc: 0.8078 - val_loss: 0.7510 - val_acc: 0.5850\n",
      "Epoch 57/100\n",
      "1800/1800 [==============================] - 1s 476us/step - loss: 0.4360 - acc: 0.8233 - val_loss: 0.7592 - val_acc: 0.5850\n",
      "Epoch 58/100\n",
      "1800/1800 [==============================] - 1s 480us/step - loss: 0.4277 - acc: 0.8244 - val_loss: 0.7650 - val_acc: 0.5800\n",
      "Epoch 59/100\n",
      "1800/1800 [==============================] - 1s 474us/step - loss: 0.4203 - acc: 0.8300 - val_loss: 0.7671 - val_acc: 0.5700\n",
      "Epoch 60/100\n",
      "1800/1800 [==============================] - 1s 529us/step - loss: 0.4116 - acc: 0.8344 - val_loss: 0.7869 - val_acc: 0.5600\n",
      "Epoch 61/100\n",
      "1800/1800 [==============================] - 1s 467us/step - loss: 0.4071 - acc: 0.8389 - val_loss: 0.7767 - val_acc: 0.5750\n",
      "Epoch 62/100\n",
      "1800/1800 [==============================] - 1s 471us/step - loss: 0.3957 - acc: 0.8544 - val_loss: 0.7959 - val_acc: 0.5600\n",
      "Epoch 63/100\n",
      "1800/1800 [==============================] - 1s 489us/step - loss: 0.3883 - acc: 0.8467 - val_loss: 0.7983 - val_acc: 0.5600\n",
      "Epoch 64/100\n",
      "1800/1800 [==============================] - 1s 475us/step - loss: 0.3807 - acc: 0.8567 - val_loss: 0.7958 - val_acc: 0.5750\n",
      "Epoch 65/100\n",
      "1800/1800 [==============================] - 1s 501us/step - loss: 0.3731 - acc: 0.8644 - val_loss: 0.7994 - val_acc: 0.5750\n",
      "Epoch 66/100\n",
      "1800/1800 [==============================] - 1s 480us/step - loss: 0.3650 - acc: 0.8589 - val_loss: 0.8069 - val_acc: 0.5800\n",
      "Epoch 67/100\n",
      "1800/1800 [==============================] - 1s 469us/step - loss: 0.3572 - acc: 0.8728 - val_loss: 0.8110 - val_acc: 0.5850\n",
      "Epoch 68/100\n",
      "1800/1800 [==============================] - 1s 489us/step - loss: 0.3502 - acc: 0.8794 - val_loss: 0.8164 - val_acc: 0.5750\n",
      "Epoch 69/100\n",
      "1800/1800 [==============================] - 1s 549us/step - loss: 0.3450 - acc: 0.8806 - val_loss: 0.8242 - val_acc: 0.5800\n",
      "Epoch 70/100\n",
      "1800/1800 [==============================] - 1s 639us/step - loss: 0.3327 - acc: 0.8844 - val_loss: 0.8328 - val_acc: 0.5950\n",
      "Epoch 71/100\n",
      "1800/1800 [==============================] - 1s 602us/step - loss: 0.3251 - acc: 0.8939 - val_loss: 0.8420 - val_acc: 0.5700\n",
      "Epoch 72/100\n",
      "1800/1800 [==============================] - 1s 490us/step - loss: 0.3175 - acc: 0.8972 - val_loss: 0.8502 - val_acc: 0.5700\n",
      "Epoch 73/100\n",
      "1800/1800 [==============================] - 1s 457us/step - loss: 0.3141 - acc: 0.8906 - val_loss: 0.8569 - val_acc: 0.5700\n",
      "Epoch 74/100\n",
      "1800/1800 [==============================] - 1s 378us/step - loss: 0.3034 - acc: 0.8972 - val_loss: 0.8660 - val_acc: 0.5900\n",
      "Epoch 75/100\n",
      "1800/1800 [==============================] - 1s 388us/step - loss: 0.2978 - acc: 0.9044 - val_loss: 0.8752 - val_acc: 0.5800\n",
      "Epoch 76/100\n",
      "1800/1800 [==============================] - 1s 388us/step - loss: 0.2901 - acc: 0.9111 - val_loss: 0.8817 - val_acc: 0.5700\n",
      "Epoch 77/100\n",
      "1800/1800 [==============================] - 1s 386us/step - loss: 0.2876 - acc: 0.9039 - val_loss: 0.8901 - val_acc: 0.5850\n",
      "Epoch 78/100\n",
      "1800/1800 [==============================] - 1s 383us/step - loss: 0.2738 - acc: 0.9139 - val_loss: 0.9135 - val_acc: 0.5700\n",
      "Epoch 79/100\n",
      "1800/1800 [==============================] - 1s 378us/step - loss: 0.2718 - acc: 0.9122 - val_loss: 0.9135 - val_acc: 0.5750\n",
      "Epoch 80/100\n",
      "1800/1800 [==============================] - 1s 377us/step - loss: 0.2610 - acc: 0.9244 - val_loss: 0.9264 - val_acc: 0.5550\n",
      "Epoch 81/100\n",
      "1800/1800 [==============================] - 1s 375us/step - loss: 0.2573 - acc: 0.9217 - val_loss: 0.9431 - val_acc: 0.5600\n",
      "Epoch 82/100\n",
      "1800/1800 [==============================] - 1s 418us/step - loss: 0.2488 - acc: 0.9300 - val_loss: 0.9501 - val_acc: 0.5600\n",
      "Epoch 83/100\n",
      "1800/1800 [==============================] - 1s 370us/step - loss: 0.2492 - acc: 0.9222 - val_loss: 0.9454 - val_acc: 0.5800\n",
      "Epoch 84/100\n",
      "1800/1800 [==============================] - 1s 369us/step - loss: 0.2429 - acc: 0.9289 - val_loss: 0.9599 - val_acc: 0.5800\n",
      "Epoch 85/100\n",
      "1800/1800 [==============================] - 1s 378us/step - loss: 0.2329 - acc: 0.9333 - val_loss: 0.9709 - val_acc: 0.5800\n",
      "Epoch 86/100\n",
      "1800/1800 [==============================] - 1s 378us/step - loss: 0.2246 - acc: 0.9400 - val_loss: 0.9774 - val_acc: 0.5700\n",
      "Epoch 87/100\n",
      "1800/1800 [==============================] - 1s 374us/step - loss: 0.2204 - acc: 0.9367 - val_loss: 1.0008 - val_acc: 0.5750\n",
      "Epoch 88/100\n",
      "1800/1800 [==============================] - 1s 370us/step - loss: 0.2159 - acc: 0.9378 - val_loss: 1.0176 - val_acc: 0.5750\n",
      "Epoch 89/100\n",
      "1800/1800 [==============================] - 1s 373us/step - loss: 0.2055 - acc: 0.9444 - val_loss: 1.0210 - val_acc: 0.5700\n",
      "Epoch 90/100\n",
      "1800/1800 [==============================] - 1s 378us/step - loss: 0.2025 - acc: 0.9472 - val_loss: 1.0247 - val_acc: 0.5950\n",
      "Epoch 91/100\n",
      "1800/1800 [==============================] - 1s 381us/step - loss: 0.1995 - acc: 0.9517 - val_loss: 1.0381 - val_acc: 0.5950\n",
      "Epoch 92/100\n",
      "1800/1800 [==============================] - 1s 385us/step - loss: 0.1885 - acc: 0.9567 - val_loss: 1.0628 - val_acc: 0.5600\n",
      "Epoch 93/100\n",
      "1800/1800 [==============================] - 1s 387us/step - loss: 0.1834 - acc: 0.9561 - val_loss: 1.0569 - val_acc: 0.5850\n",
      "Epoch 94/100\n",
      "1800/1800 [==============================] - 1s 405us/step - loss: 0.1796 - acc: 0.9589 - val_loss: 1.0944 - val_acc: 0.5750\n",
      "Epoch 95/100\n",
      "1800/1800 [==============================] - 1s 403us/step - loss: 0.1738 - acc: 0.9617 - val_loss: 1.0885 - val_acc: 0.5650\n",
      "Epoch 96/100\n",
      "1800/1800 [==============================] - 1s 382us/step - loss: 0.1697 - acc: 0.9644 - val_loss: 1.1106 - val_acc: 0.5550\n",
      "Epoch 97/100\n",
      "1800/1800 [==============================] - 1s 430us/step - loss: 0.1665 - acc: 0.9622 - val_loss: 1.1221 - val_acc: 0.5550\n",
      "Epoch 98/100\n",
      "1800/1800 [==============================] - 1s 380us/step - loss: 0.1617 - acc: 0.9661 - val_loss: 1.1448 - val_acc: 0.5750\n",
      "Epoch 99/100\n",
      "1800/1800 [==============================] - 1s 389us/step - loss: 0.1567 - acc: 0.9661 - val_loss: 1.1466 - val_acc: 0.5600\n",
      "Epoch 100/100\n",
      "1800/1800 [==============================] - 1s 376us/step - loss: 0.1530 - acc: 0.9678 - val_loss: 1.1580 - val_acc: 0.5700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd7cbc6d780>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y,\n",
    "          epochs=100,\n",
    "          verbose=1, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
